{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bedrock model integration with Langchain Agents \n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio on ml.t3.medium instance*\n",
    "\n",
    "\n",
    "### Financial stock analyzer example  \n",
    "\n",
    "Certain applications demand an adaptable sequence of calls to language models and various utilities depending on user input. The Agent interface enables such flexibility for these applications. An agent has availability to a range of resources and selects which ones to utilize based on the user input. Agents are capable of using multiple tools and utilizing the output of one tool as the input for the next.  \n",
    "\n",
    "There are two primary categories of agents:\n",
    "\n",
    "- Action agents: At each interval, determine the subsequent action utilizing the outputs of all previous actions. \n",
    "- Plan-and-execute agents: Determine the complete order of actions initially, then implement them all without updating the plan.\n",
    "\n",
    "In this notebook, we will demonstrate the use `Zero-shot ReAct` agent based on [`ReAct`](https://arxiv.org/pdf/2205.00445.pdf) framework to select the appropriate tool based exclusively on the tool's description. It requires you provide the description of each tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "⚠️ ⚠️ ⚠️ Before running this notebook, ensure you've run the [Bedrock boto3 setup notebook](1_setup.ipynb) notebook. ⚠️ ⚠️ ⚠️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import re\n",
    "from functools import partial\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock\n",
    "\n",
    "from langchain.chat_models import BedrockChat\n",
    "from typing import Optional, List, Any\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "model_parameter = {\"temperature\": 0.0, \"top_p\": .5, \"max_tokens\": 2000}\n",
    "llm = BedrockChat(model_id=model_id, client=boto3_bedrock, model_kwargs=model_parameter, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Prepare dataset in SQLite Database\n",
    "First we will create some sample data for stock analysis in SQLite database. This will later serve as a tool for our agent to look up information about stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Create Sample data for subsequent SQL query usage\n",
    "\n",
    "stock_ticker_data=[ \n",
    "    {\n",
    "        \"symbol\" : \"PRAA\",\n",
    "        \"name\" : \"PRA Group, Inc.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"AMZN\",\n",
    "        \"name\" : \"Amazon.com, Inc.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"TSLA\",\n",
    "        \"name\" : \"Tesla Inc.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"PAAS\",\n",
    "        \"name\" : \"Pan American Silver Corp.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"PAAC\",\n",
    "        \"name\" : \"Proficient Alpha Acquisition Corp.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqCM\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"RYAAY\",\n",
    "        \"name\" : \"Ryanair Holdings plc\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"MPAA\",\n",
    "        \"name\" : \"Motorcar Parts of America, Inc.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"STAA\",\n",
    "        \"name\" : \"STAAR Surgical Company\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGM\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"RBCAA\",\n",
    "        \"name\" : \"Republic Bancorp, Inc.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"AABA\",\n",
    "        \"name\" : \"Altaba Inc.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGS\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"    \n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"AAXJ\",\n",
    "        \"name\" : \"iShares MSCI All Country Asia ex Japan ETF\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGM\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }, \n",
    "    {\n",
    "        \"symbol\" : \"ZNWAA\",\n",
    "        \"name\" : \"Zion Oil & Gas, Inc.\",\n",
    "        \"currency\" : \"USD\",\n",
    "        \"stockExchange\" : \"NasdaqGM\",\n",
    "        \"exchangeShortName\" : \"NASDAQ\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#sqllite3 Python library that provides a lightweight disk-based database that doesn’t require a separate server process\n",
    "import sqlite3\n",
    "\n",
    "#Creating a function for Db connection\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except FileExistsError as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Creating a function for table creation\n",
    "def run_sql(conn, sql_query):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(sql_query)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Create a Database Connection\n",
    "db_name = \"stock_ticker_database.db\"\n",
    "conn = create_connection(db_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_table_sql = \"\"\"DROP TABLE IF EXISTS stock_ticker;\"\"\"\n",
    "\n",
    "#Create Table Query\n",
    "create_table_sql = \"\"\"CREATE TABLE stock_ticker (\n",
    "\tsymbol text PRIMARY KEY,\n",
    "\tname text NOT NULL,\n",
    "\tcurrency text,\n",
    "\tstockExchange text, \n",
    "    exchangeShortName text\n",
    ");\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calling create table user defined function\n",
    "if conn is not None:\n",
    "    # drop existing table\n",
    "    run_sql(conn, drop_table_sql)\n",
    "    \n",
    "    # create projects table\n",
    "    run_sql(conn, create_table_sql)\n",
    "else:\n",
    "    print(\"Error! cannot create the database connection.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Insert the data created in the previous step. \n",
    "def insert_data(data):\n",
    "    for item in data:\n",
    "        conn.execute(\"INSERT INTO stock_ticker (symbol, name, currency,stockExchange, exchangeShortName ) VALUES (?, ?, ?, ?,?)\", \n",
    "                    (item[\"symbol\"], item[\"name\"], item[\"currency\"], item[\"stockExchange\"],item[\"exchangeShortName\"]))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# uncomment to insert data if the data doesn't exist in the table.\n",
    "insert_data(stock_ticker_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Database Tools\n",
    "A common use of an agent is to look up a record in a database. It would not be practical to include the full database in the context, so you can provide tools that perform actions against the datebase that eliminates hallucinations while maintaining the conversational interactions.\n",
    "\n",
    "### SQL Database Tool\n",
    "The [LangChain](https://python.langchain.com/docs/get_started/introduction) includes tools to help build application that interact with relational databases. For details, read this document: https://python.langchain.com/docs/integrations/toolkits/sql_database\n",
    "\n",
    "In the example below we will construct a workflow or a chain in LangChain parlance that will look up a stock in the SQLite database. Specifically this chain will be comprised of 3 steps:\n",
    "- Step 1: Generate a SQL query given a user question and the database schema\n",
    "- Step 2: Execute the query against the database\n",
    "- Step 3: Generate a response based on the query results\n",
    "\n",
    "We will subsequently use this chain as a tool in our agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a langchain database instance\n",
    "db = SQLDatabase.from_uri(\"sqlite:///stock_ticker_database.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper function below will help us extract specific text contained within an XML tag. LLMs have a tendency to generate extra text that is not relevant to the user query. To get around this we will instruct the model to output the SQL query into an XML tag and use the function below to extract the SQL query from the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_from_xml_tag(response:str, tag:str) -> str:\n",
    "    \n",
    "    \"\"\"Extract the text from the specified XML tag in the response string.\"\"\"\n",
    "    \n",
    "    tag_txt = re.search(rf'<{tag}>(.*?)</{tag}>', response, re.DOTALL)\n",
    "    if tag_txt:\n",
    "        return tag_txt.group(1)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a prompt that will be used to instruct the model to generate the SQL query. LangChain will automatically construct the relevant chain based on the prompt and the schema information captured from the `db` object that was created earlier. We will use the [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/get_started/) to add an additional step to the chain that will extract the SQL query from the <sql> XML tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "sql_template = \"\"\"You are a ANSI SQL expert with access to a database with the following tables: \n",
    "\n",
    "<schema>\n",
    "{table_info}\n",
    "</schema>\n",
    "\n",
    "Generate a SQL Query that retrieves the top {top_k} records. Do not explain the query, just output the SQL.\n",
    "Place the output into <sql>...</sql> tags.\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "sql_prompt = ChatPromptTemplate.from_template(sql_template)\n",
    "\n",
    "query_writer_chain = create_sql_query_chain(llm, db, prompt=sql_prompt, k=100)\n",
    "\n",
    "extract_sql = partial(extract_from_xml_tag, tag=\"sql\")\n",
    "\n",
    "query_writer_chain = query_writer_chain | RunnableLambda(extract_sql) # extract the SQL query from the response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's test if the query generation chain works\n",
    "query_writer_chain.invoke({\"question\": \"Retrieve the top 5 records from the stock_ticker table.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to add a step to execute the generated SQL query. Fortunately LangChain already has a built-in [QuerySQLDataBaseTool](https://api.python.langchain.com/en/latest/tools/langchain_community.tools.sql_database.tool.QuerySQLDataBaseTool.html) which does exactly this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's test if the query works\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "execute_query.invoke({\"query\": \"SELECT * FROM stock_ticker LIMIT 5;\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to create a prompt that will take the output from the SQL Execution step and generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "<question> {question} </question>\n",
    "<sql> \n",
    "{query} \n",
    "</sql>\n",
    "<result>\n",
    "{result}\n",
    "</result>\n",
    "\n",
    "Provide a response to the question. Do not provide any additional information, do not explain the SQL query, and do not say that the results came from a SQL query. \n",
    "The user has no knowledge of the backend data systems and mention of SQL will confuse them.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "answer_chain = answer_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the 3 steps into a single chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_sql_chain = (\n",
    "    RunnablePassthrough.assign(query=query_writer_chain).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(full_sql_chain.invoke({\"question\":\"What is the ticker symbol for Tesla in stock ticker table?\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Construct the tools for the ReACt agent\n",
    "In this section we will define multiple functions that will act as tools that our agent can use to address the user's task. We will define the following tools:\n",
    "- `get_stock_ticker`: This tool will look up a stock in the SQLite database using the SQL chain we defined earlier\n",
    "- `get_stock_price`: This tool will look up the price of a stock ticker using an external API\n",
    "- `get_stock_news`: This tool will look up the latest news about a stock ticker using an external API\n",
    "- `get_financial_statements`: This tool will look up the financial statements of a stock ticker using an external API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from langchain.agents import load_tools, AgentType, Tool, initialize_agent\n",
    "from pandas_datareader import data as pdr\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "\n",
    "yf.pdr_override()\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "def get_stock_ticker(query, db_chain=full_sql_chain):\n",
    "    \"\"\"\n",
    "    Returns the ticker symbol and company name relevant to the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): The query to find the relevant ticker symbol and company name.\n",
    "        db_chain (Chain, optional): The database chain to use. Defaults to full_sql_chain.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the company name and ticker symbol.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = db_chain.invoke(\n",
    "        {\n",
    "            \"question\": f\"Return the ticker symbol and company name that is relevant to this query {query}. Place symbol into <symbol>...</symbol> tags and company name into <company>...</company> tags.\"\n",
    "        }\n",
    "    )\n",
    "    symbol = extract_from_xml_tag(response, \"symbol\")\n",
    "    company_name = extract_from_xml_tag(response, \"company\")\n",
    "\n",
    "    return company_name, symbol\n",
    "\n",
    "\n",
    "def get_stock_price(ticker, history=10):\n",
    "    \"\"\"\n",
    "    Returns the stock data for the specified ticker symbol.\n",
    "\n",
    "    Args:\n",
    "        ticker(str): The ticker symbol for which to fetch the stock data.\n",
    "        history(int): The number of days of historical data to fetch. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the stock data and a unique name.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(ticker)\n",
    "    today = date.today()\n",
    "    start_date = today - timedelta(days=history)\n",
    "    data = pdr.get_data_yahoo(ticker, start=start_date, end=today)\n",
    "    dataname = ticker + \"_\" + str(today)\n",
    "\n",
    "    return data, dataname\n",
    "\n",
    "\n",
    "# Fetch top 5 google news for given company name\n",
    "def google_query(search_term):\n",
    "\n",
    "    if \"news\" not in search_term:\n",
    "        search_term = search_term + \" stock news\"\n",
    "    url = f\"https://www.google.com/search?q={search_term}\"\n",
    "    url = re.sub(r\"\\s\", \"+\", url)\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_recent_stock_news(company_name):\n",
    "    \"\"\"\n",
    "    Fetches and returns the top 5 recent news articles for a given company from Google News.\n",
    "\n",
    "    Args:\n",
    "        company_name (str): The name of the company to fetch news for.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the top 5 recent news articles for the company.\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    g_query = google_query(company_name)\n",
    "    res = requests.get(g_query, headers=headers).text\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    news = []\n",
    "    for n in soup.find_all(\"div\", \"n0jPhd ynAwRc tNxQIb nDgy9d\"):\n",
    "        news.append(n.text)\n",
    "    for n in soup.find_all(\"div\", \"IJl0Z\"):\n",
    "        news.append(n.text)\n",
    "\n",
    "    if len(news) > 6:\n",
    "        news = news[:4]\n",
    "    else:\n",
    "        news = news\n",
    "    news_string = \"\"\n",
    "    for i, n in enumerate(news):\n",
    "        news_string += f\"{i}. {n}\\n\"\n",
    "    top5_news = \"Recent News:\\n\\n\" + news_string\n",
    "\n",
    "    return top5_news\n",
    "\n",
    "\n",
    "def stock_news_search(company_name):\n",
    "    search = DuckDuckGoSearchRun()\n",
    "    return search(\"Stock news about \" + company_name)\n",
    "\n",
    "\n",
    "# Get financial statements from Yahoo Finance\n",
    "def get_financial_statements(ticker):\n",
    "    \"\"\"\n",
    "    Fetches and returns the balance sheet for a given company ticker from Yahoo Finance.\n",
    "\n",
    "    Args:\n",
    "        ticker (str): The ticker of the company to fetch the balance sheet for.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the company's balance sheet.\n",
    "    \"\"\"\n",
    "\n",
    "    if \".\" in ticker:\n",
    "        ticker = ticker.split(\".\")[0]\n",
    "    else:\n",
    "        ticker = ticker\n",
    "    company = yf.Ticker(ticker)\n",
    "    balance_sheet = company.balance_sheet\n",
    "    if balance_sheet.shape[1] >= 3:\n",
    "        balance_sheet = balance_sheet.iloc[:, :3]  # Only captures last 3 years of data\n",
    "    balance_sheet = balance_sheet.dropna(how=\"any\")\n",
    "    balance_sheet = balance_sheet.to_string()\n",
    "    return balance_sheet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by testing out some of these tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look up a stock ticker for a company given an arbitrary query\n",
    "company_name, company_ticker = get_stock_ticker(\"What is the main business of Amazon?\")\n",
    "print(\"Company Name: \", company_name)\n",
    "print(\"Company Ticker: \", company_ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(get_stock_price(\"AMZN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(get_recent_stock_news(\"Amazon\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(get_financial_statements(\"AMZN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(stock_news_search(\"Amazon\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building an Agent, let's combine all of these tools into a static prompt to see how an LLM could make use of the information provided by these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def analyze_stock(query):\n",
    "    \n",
    "    \"\"\"Construct a chain that will always invoke all of the tools and use the output to respond to the user query.\"\"\"\n",
    "    \n",
    "    company_name, ticker = get_stock_ticker(query)\n",
    "    print({\"Query\": query, \"company_name\": company_name, \"Ticker\": ticker})\n",
    "    stock_data = get_stock_price(ticker, history=10)\n",
    "    stock_financials = get_financial_statements(ticker)\n",
    "    stock_news = get_recent_stock_news(company_name)\n",
    "\n",
    "    analysis_template = \"\"\"\n",
    "    Given detail stock analysis, Use the available data and provide investment recommendation. \n",
    "    The user is fully aware about the investment risk, do not include any kind of warning like \n",
    "    'It is recommended to conduct further research and analysis or consult with a financial advisor before making an investment decision' in the answer. \n",
    "    User question: {query}. You have the following information available about {company_name}. \n",
    "    Write (5-8) point investment analysis to answer user query, At the end conclude with proper explanation. \n",
    "    Try to Give positives and negatives: \n",
    "    <stock_price>\n",
    "    {stock_data}\n",
    "    </stock_price> \n",
    "    \n",
    "   <stock_financials>\n",
    "   {stock_financials}\n",
    "   <stock_financials>\n",
    "    \n",
    "    \n",
    "    <stock_news>\n",
    "    {stock_news}\n",
    "    </stock_news>\n",
    "    \n",
    "    Provide an analysis only base on the information provided above. Do not use any other external information or your own knowledge as the basis for the analysis.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    analysis_prompt = ChatPromptTemplate.from_template(analysis_template)\n",
    "    analysis_chain = analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "    analysis = analysis_chain.invoke(\n",
    "        {\n",
    "            \"query\": query,\n",
    "            \"company_name\": company_name,\n",
    "            \"stock_data\": stock_data,\n",
    "            \"stock_financials\": stock_financials,\n",
    "            \"stock_news\": stock_news,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "analyze_result=analyze_stock(\"Is Amazon a good investment choice right now?\")\n",
    "print(analyze_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Using ReAct: Synergizing Reasoning and Acting in Language Models Framework\n",
    "Large language models can generate both explanations for their reasoning and task-specific responses in an alternating fashion. \n",
    "\n",
    "Producing reasoning explanations enables the model to infer, monitor, and revise action plans, and even handle unexpected scenarios. The action step allows the model to interface with and obtain information from external sources such as knowledge bases or environments.\n",
    "\n",
    "The ReAct framework could enable large language models to interact with external tools to obtain additional information that results in more accurate and fact-based responses.\n",
    "\n",
    "In this section, rather than hardcoding the tools into a static chain, we will use the ReAct framework to select the appropriate tool based exclusively on the tool's description and the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# A few additional imports to build the agent\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent, Tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When instantiating the ReAct agent, we will provide a list of tools and their descriptions. The agent will then select the appropriate tool based on the user input and the tool's description. We can provide this information by wrapping the tools in a `Tool` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tools=[\n",
    "    Tool(\n",
    "        name=\"get_stock_ticker\",\n",
    "        func=get_stock_ticker,\n",
    "        description=\"Get the company stock ticker\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_stock_price\",\n",
    "        func=get_stock_price,\n",
    "        description=\"Use when you are asked to evaluate or analyze a stock. This will output historic share price data. You should input the the stock ticker to it \"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_recent_stock_news\",\n",
    "        func=get_recent_stock_news,\n",
    "        description=\"Use this to fetch recent news about stocks\"\n",
    "    ),\n",
    "\n",
    "    Tool(\n",
    "        name=\"get_financial_statements\",\n",
    "        func=get_financial_statements,\n",
    "        description=\"Use this to get financial statement of the company. With the help of this data companys historic performance can be evaluaated. You should input stock ticker to it\"\n",
    "    ) \n",
    "\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that in tool functions that we defined earlier, we wrote docstrings in the [Google-style format](https://google.github.io/styleguide/pyguide.html). To avoid duplication, we can use a pair of helper functions `extract_docstring_info` and `construct_format_tool_for_claude_prompt` to parse the docstring and convert it into a tool calling prompt format prescribed by the [Claude documentation](https://docs.anthropic.com/claude/docs/legacy-tool-use)\n",
    "\n",
    "**Note:** The prompt based approach below for tool usage is now considered legacy. Anthropic introduced a json base format for tools as documented [here](https://docs.anthropic.com/claude/docs/tool-use-examples). This example will be updated once the Bedrock API and Langchain support the new format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.prompt_utils import extract_docstring_info, construct_format_tool_for_claude_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_prompt = \"\"\n",
    "for tool in tools:\n",
    "    docstring_info = extract_docstring_info(tool.func.__doc__)\n",
    "    tool_prompt += construct_format_tool_for_claude_prompt(tool.name, docstring_info['description'], docstring_info['params'])\n",
    "\n",
    "print(tool_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct a prompt that will be used to instruct the model to select the appropriate tool based on the tool's description and the user input which will be injected based on the XML generated above. We are also providing placeholders for the chat history and the intermediate reasoning steps within the `{agent_scratchpad}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_prompt_template = \"\"\"You are a financial advisor who has access to a set of tools that can help answer questions about stocks and investments.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You may invoke any tool like this:\n",
    "<tool>$TOOL_NAME</tool><tool_input>$PARAMETER_VALUE</tool_input>\n",
    "For example to use the tool 'get_stock_ticker', you would invoke it like this:\n",
    "<tool>get_stock_ticker</tool>\n",
    "<tool_input>\"What is the main business of Amazon?\"</tool_input>\n",
    "<observation>Amazon.com, Inc., AMZN</observation>\n",
    "\n",
    "When you are done, respond with a final answer between <final_answer></final_answer>. For example:\n",
    "\n",
    "<final_answer>Investment Analysis of Amazon.com, Inc. (AMZN)</final_answer>\n",
    "\n",
    "Make sure you make use of all the tools available to you and not bias your answer based on an output from a single tool or your own knowledge.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Previous Conversation:\n",
    "{chat_history}\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "agent_prompt = ChatPromptTemplate.from_template(agent_prompt_template, partial_variables={\"chat_history\": \"\", \"tools\": tool_prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_intermediate_steps(intermediate_steps):\n",
    "    \"\"\"\n",
    "    Helper function to convert the intermediate reasoning steps to xml format that Claude is better able to understand.\n",
    "    \"\"\"\n",
    "    \n",
    "    log = \"\"\n",
    "    for action, observation in intermediate_steps:\n",
    "\n",
    "        log += (\n",
    "            f\"<tool>{action.tool}</tool><tool_input>{action.tool_input}\"\n",
    "            f\"</tool_input><observation>{observation}</observation>\"\n",
    "        )\n",
    "    return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the prompt, model, and the intermediate steps conversion function into a single chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.output_parsers import XMLAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: convert_intermediate_steps(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | agent_prompt\n",
    "    | llm.bind(stop=[\"</tool_input>\", \"</final_answer>\"])\n",
    "    | XMLAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancgain provides a built-in [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html) to construct the agent. This executor will essentially invoke the chain defined above until it generates the `<final_answer>` response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_response = agent_executor.invoke({\"input\": \"Is Tesla a good investment choice right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(agent_response[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
